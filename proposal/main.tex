\documentclass[a4paper,10pt]{article}

%page geometry
\usepackage[colorlinks,linkcolor=blue,citecolor=blue,urlcolor=blue]{hyperref}
\usepackage[lmargin=2cm,rmargin=2cm,tmargin=1.25cm,bmargin=1.25cm,includefoot,includehead]{geometry}

%typography
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
%% Serif Times fonts
\renewcommand{\rmdefault}{ptm} 
%% Sans-serif Arial-like fonts (Helvetica)
\renewcommand{\sfdefault}{phv} 

%text structures
\usepackage{enumitem}
\usepackage{tabu}
\usepackage[dvipsnames]{xcolor}
\usepackage{tcolorbox}
\usepackage{colortbl}
\usepackage{graphicx}
\usepackage{eurosym}
\usepackage{xspace}

\usepackage{tabularx}
\usepackage{boxedminipage}
\usepackage{spreadtab}



%uncomment if you want to draw a Gantt diagram
%\usepackage{pgfgantt}



%couleurs ARN 
\definecolor{ANRblue}{HTML}{004d95}
\definecolor{ANRred}{HTML}{FF0000}
\definecolor{ANRpurple}{HTML}{800080}


%physique-chimie
\usepackage{siunitx} %unités en \SI{10}{\micro\metre}
\usepackage[version=3]{mhchem} % Formula subscripts using \ce{}

\usepackage{csquotes}

%commandes pour dire qui doit faire quoi
\newcommand{\Mathieu}[1]{\textcolor{orange}{#1}}
\newcommand{\Helene}[1]{\textcolor{purple}{#1}}

% %biblio
%\usepackage[backend=biber,style=numeric-comp, language=british,eprint=false, url=false, doi=false, sortcites=true, sorting=none, isbn=false, firstinits=true,maxbibnames=99]{biblatex}
%\renewbibmacro{in:}{%
%  \ifentrytype{article}{}{%
%  \printtext{\bibstring{in}\intitlepunct}}}
%\bibliography{pre-propal-2017}
%\bibliographystyle{plain}

%no month
%\AtEveryBibitem{\clearfield{month}}

%\addbibresource{IEEEabrv.bib}

%lien DOI ou URL si disponible
%\newbibmacro{string+doi}[1]{%
%  \iffieldundef{doi}{%
%    \iffieldundef{url}{#1}{\href{\thefield{url}}{#1}}}{\href{http://dx.doi.org/%\thefield{doi}}{#1}}}

%sur le titre, en couleur
%\DeclareFieldFormat
%  [article,inbook,incollection,inproceedings,patent,thesis,unpublished]
%  {title}{{\textcolor{ANRblue}{#1\addperiod}}}
  

%Our names in bold
\usepackage{xstring}
\usepackage{etoolbox}
%\newboolean{bold}
%% \newcommand{\makeauthorsbold}[1]{%
%% \DeclareNameFormat{author}{%
%%     \setboolean{bold}{false}%
%%     \renewcommand{\do}[1]{\ifstrequal{##1}{####1}{\setboolean{bold}{true}}{}}%
%%     \docsvlist{#1}%
%%     \ifnumequal{\value{listcount}}{1}%
%%     {\ifnumequal{\value{liststop}}{1}%Single author
%%       {\expandafter\ifthenelse{\boolean{bold}}{\textcolor{ANRpurple}{\underline{##1\addcomma\addspace ##4\addcomma\isdot}}}{##1\addcomma\addspace ##4\addcomma\isdot}}
%%       %first author
%%       {\expandafter\ifthenelse{\boolean{bold}}{\textcolor{ANRpurple}{\underline{##1\addcomma\addspace ##4}}}{##1\addcomma\addspace ##4}}}
%%       %last author
%%     {\ifnumless{\value{listcount}}{\value{liststop}}
%%       {\expandafter\ifthenelse{\boolean{bold}}{\addcomma\addspace \textcolor{ANRpurple}{\underline{##1\addcomma\addspace ##4}}}{\addcomma\addspace ##1\addcomma\addspace ##4}}
%%       %middle author
%%           {\expandafter\ifthenelse{\boolean{bold}}{\addcomma\addspace \textcolor{ANRpurple}{\underline{##1\addcomma\addspace ##4\addcomma\isdot}}}{\addcomma\addspace ##1\addcomma\addspace ##4\addcomma\isdot}}%
%%     }%
%% }%
%% }
%% \makeauthorsbold{Cottin-Bizonne,Delanoë-Ayari,Leocmach}

%% %%hack fullcite so that it prints all authors
%% \makeatletter
%% \DeclareCiteCommand{\fullcite}
%%   {\defcounter{maxnames}{\blx@maxbibnames}%
%%     \usebibmacro{prenote}}
%%   {\usedriver
%%      {\DeclareNameAlias{sortname}{default}}
%%      {\thefield{entrytype}}}
%%   {\multicitedelim}
%%   {\usebibmacro{postnote}}
%% \makeatother

\newcolumntype{P}[1]{>{\raggedright}p{#1}}

%% section title format, in the text and in the table of content
\usepackage{tocloft}

\renewcommand{\cfttoctitlefont}{\color{ANRblue}\normalfont\scshape\bfseries\sffamily\Large}

\usepackage{titlesec}
\titleformat{\section}
{\color{ANRpurple}\normalfont\scshape\bfseries\sffamily\Large}
{\color{ANRpurple}\thesection}{1em}{}
\renewcommand{\cftsecfont}{\color{ANRpurple}\normalfont\scshape\bfseries\sffamily\large}

\titleformat{\subsection}
{\color{ANRblue}\normalfont\scshape\bfseries\sffamily\large}
{\color{ANRblue}\thesubsection}{1em}{}
\renewcommand{\cftsubsecfont}
{\color{ANRblue}\normalfont\scshape\bfseries\sffamily}

\titleformat{\subsubsection}
{\color{ANRpurple}\normalfont\bfseries\sffamily}
{\color{ANRpurple}\thesubsubsection}{1em}{}
\renewcommand{\cftsubsubsecfont}
{\color{ANRpurple}\normalfont\bfseries\sffamily\small}

\titleformat{\paragraph}[runin]
{\color{ANRblue}\normalfont\sffamily}
{\color{ANRblue}\theparagraph}{1em}{}

\newcommand{\F}{\textsc{Faust}}
\newcommand{\PP}{our project}

%titre, acronyme, défi, instrument
\newcommand{\myacro}[0]{XXXX}
\newcommand{\mytitle}[0]{\myacro: \\The long title of the ANR project}
\newcommand{\projectname}[0]{XXXX}
\newcommand{\mydomain}[0]{8.6}
\newcommand{\myinstrument}[0]{PRC}
\author{Coordinateur: Romain Michon\\
\small GRAME-CNCM, Lyon.
}

%% Headers
\usepackage{fancyhdr}
\pagestyle{fancy}
%\fancyhfoffset[re]{4cm}
\lhead{\myacro\\ Domaine \mydomain{} - \myinstrument}
\rhead{\LARGE\textcolor{ANRblue}{AAPG ANR 2019}}
\renewcommand{\headrulewidth}{0pt}

\lfoot{}
\cfoot{}
\rfoot{\thepage}%/\pageref{LastPage}} 




\title{\vspace{-\baselineskip}\mytitle}
\date{Domaine transversaux\\
Axe 8.6 - Révolution numérique : rapports au savoir et à la culture}

\newcommand{\content}[1]{\emph{#1}\\} 


\begin{document}
\maketitle
\thispagestyle{fancy}



%\section{Executive summary }
\begin{tabular}{p{2.3cm} p{12cm}}
  \hline
  \textbf{Keywords} &   \\\hline
  \textbf{Challenge and Axe (?? A REVOIR)} & 
  \\\hline
\end{tabular}


%\section{Contexte, positionnement et objectif(s) de la proposition}
\section{Context, position and objectives of the proposal}

Real-time audio Digital Signal Processing (DSP) is used at the core of many systems ranging from musical instruments to active acoustics correction technologies, speakers, etc. Latency plays a crucial role in this context.  In the domain of music, wether we're talking about a digital mixing desk, a musical instrument (e.g., synthesizers, effects/guitar pedals, etc.), or a digital speaker or microphone, the perception of latency can have a significant impact on playability \cite{Lago2004}. In the domain of active control applied to acoustics where it is typically necessary to ``beat'' acoustical waves by processing signals faster than the speed of sound, low latency is a determining factor \cite{TODO}.  

While audio processing latency can be reduced on ``standard'' computing platforms (i.e., personal computers based on CPU\footnote{\textit{Central Processing Unit}}s by using dedicated hardware (i.e., audio interfaces, etc.) and software (i.e., low-latency Linux kernels, etc.) solutions, buffering remains a limiting factor and going under the ``one millisecond threshold'' (which corresponds to a distance of about 35cm in the air) is usually impossible. Various alternatives based on specific computing platforms such as DSPs, microcontrollers, CPU-based computers used without an Operating System (OS) ``bare-metal'', etc. can help to further reduce audio latency. However, Field Programmable Gate Arrays (FPGAs) can be seen as the most radical and efficient technology in this context by providing a buffer-less straight computational path. 

FPGAs are increasingly used in the context of real-time audio DSP both in the industry (i.e., Antelope Audio,\footnote{\url{https://en.antelopeaudio.com/}} Korora Audio,\footnote{\url{https://www.kororaaudio.com/}} and in academia, mostly for their computational capabilities \cite{Choi2013,Pfeifle2012} and in some rarer cases for their low-latency performances \cite{Verstraelen2014}. Similarly, FPGA-based boards specifically targeting audio applications such as Dada Machines' Doppler\footnote{\url{https://dadamachines.com/product/doppler/}} are starting to appear. 

FPGAs are configured/programmed using a Hardware Description Language (HDL) such as VHDL or Verilog. The learning curve and the electrical engineering skills required to master these types of environments make them out of reach to the real-time audio DSP community. While there exists solutions to program FPGAs at a higher level (i.e., LabVIEW,\footnote{\url{https://www.ni.com/fr-fr/shop/labview.html}} Vivado HLS,\footnote{\url{https://www.xilinx.com/HLS}} etc.), none of them is specifically dedicated nor adapted to real-time audio DSP. 

\F{} \cite{Orlarey2009} is a Domain Specific Language (DSL) for real-time audio signal processing primarily developed at GRAME-CNCM and by a worldwide community. \F{} is based on a compiler ``translating'' DSP specifications written in \F{} into a wide range of lower-level languages (e.g., C, C++, Rust, Java, WASM, LLVM bitcode, etc.). Thanks to its ``architecture'' system, generated DSP objects can be embedded into template programs (wrappers) used to turn a \F{} program into a specific ready-to-use object (e.g., standalone, plug-in, smartphone app, webpage, etc.). In a previous project (SyFaLa\footnote{TODO: do we have a website for SyFaLa? What info do we want to provide here?}), we used Vivado HLS to synthesize a DSP IP from the C++ code generated by the \F{} compiler to program an FPGA development board (Zybo Z7). The entire process was automatized and it is now possible to run a \F{} program to carry out real-time sound synthesis or processing on one of these boards just by running a single command line. While using \F{} significantly simplifies the process of programming the FPGA making this task accessible to the audio, DSP, and DIY communities, generated IPs are quiet inefficient, partly because of floating point operations. Moreover, the audio codec (Analog Devices SSM2603) provided on the Zybo Z7 only has a stereo input and output and its internal latency is not that good (the measured analog audio input to analog audio output latency after processing on the FPGA ``roundtrip'' is about $800\mu s$ and is mostly due to the audio codec).

The main goal of \PP{} is to develop a platform for ultra-low-latency multichannel (> 16 audio inputs and outputs) high-performance audio processing programmable at a high level using \F{}. This implies the development of an FPGA-based device with multiple audio inputs and outputs (we aim for 64 of each) using low-latency audio codecs. In parallel, an extended investigation on optimizing the IP generated by \F{} will have to be carried out. In particular, allowing fixed-point support in the code generated by the \F{} compiler should be implemented. Eventually, we aim at generating VHDL code directly from the \F{} compiler. % RM: not sure if we want to leave that last sentence

This type of system has a wide range of applications in multiple domains. As mentioned earlier, music technology is in high demand for low latency because it helps increasing the playability of musical instruments on stage. Hence, the platform developed as part of \PP{} could be used to design programmable digital musical instruments and effect processors. In that context, the computational power of the FPGA could be exploited to run complex algorithms (e.g., physical models of musical instruments, modal reverbs, etc.) that are too costly to run on a traditional platform (i.e., laptop, etc.). GRAME-CNCM has decades of experience in that domain. We plan to implement a sound synthesis/processor module based on the platform implemented in \PP{}.

Other fields of application for the platform that we plan to develop as part of \PP{} is active control of acoustical spaces (e.g., noise cancellation in rooms, car passenger compartment, etc.) and virtual room acoustics (e.g., to apply the acoustical properties of a space to another, etc.). Sound field rendering systems are in high demand for low audio latency (i.e., to beat acoustical waves traveling at the speed of sound in the air) and high computational power (i.e., to implement Finite Difference Time Domain: FDTD schemes). While FPGAs have been used in the past for this type of applications \cite{Tan2019}, there is a lack for a high level tool to program and implement these types of algorithms. Similarly, FPGAs should allow to run in real-time room acoustics simulation algorithms in the time domain such as modal reverbs \cite{Abel2019}, which is not currently possible on regular computers. LMFA École Centrale with Pierre Lecomte has a lot of experience in these domains and a wide range of equipments at its disposal (e.g., sound field array, etc.) that could be used/adapted to this purpose. We plan to prototype real-world examples of room acoustics simulation/modifications that could then be used in a concert setting. Such experiments have been attempted in that past at the Center for Computer Research in Music and Acoustics (CCRMA) at Stanford University who's indirectly related to \PP{} thanks to Romain Michon's affiliation. In particular, the acoustics of the Hagia Sophia cathedral in Istanbul has been recreated in Stanford's Bing Concert Hall for a series of concerts centered around the idea of ``archeoacoustics.'' \cite{Abel2009} The platform that we plan to implement as part of \PP{} could be used to take this type of system to a completely different level, hence we plan to organize events centered around these concepts with the help of GRAME-CNCM music production department.

Finally, applications around active control are not limited to acoustical space. Musical instrument acoustics/digital lutherie are increasingly using these types of techniques \cite{Zhang2018} not to mention industrial applications outside of the field of audio (e.g., aircraft jet engine vibration control, etc.) which would be easily reachable thanks to LMFA's expertise in these domains.

% Say something about mediation at Grame and opening these technologies to a larger audience: scientific culture. Same for performative aspect: virtual room acoustics in concert situation.


%Sur une page et demie (1,5) environ, 
%Décrire les objectifs et les hypothèses scientifiques
%Montrer l’originalité et la pertinence par rapport à l’état de l’art
%Décrire la méthodologie et la gestion des risques

\begin{figure}[h]
  \centerline{Il faut mettre des figure, ça fixe les idées}
    \caption{Il faut mettre des figure, ça fixe les idées (sagesse populaire)}
\label{fig1}
\end{figure}
%\section{Organisation du projet et moyens mis en œuvre}
\section{Project organization and implementation}

The project will be led by Romain Michon (GRAME-CNCM,\footnote{\url{http://grame.fr}} Lyon, France // CCRMA,\footnote{\url{https://ccmra.stanford.edu}} Stanford University, USA). GRAME is a ``Centre National de Création Musicale'' (CNCM) organized in three departments: music production, transmission/mediation, and research. GRAME's research department has been leading the development of the \F{} programming language since its creation in 2004. It has expertise in computer science (compilation), audio DSP, digital lutherie, and HCI (Human Computer Interaction) in general. Thanks to the proximity of all three departments at GRAME, research outcomes can easily find their way to professional musical productions and be shared with a general public through the organization of workshops and tight collaborations with the French ministry of education. Hence, the planning of concerts and outreach events around scientific culture leveraging the technology and research outcomes of \PP{} will be facilitated by GRAME's general structure and strike force. Romain Michon has been working on \F{}, digital lutherie, and embedded systems for real-time audio applications for many years. Yann Orlarey who's the father of \F{} and GRAME's scientific director will participate in the project as well. Similarly, Stéphane Letz who's a researcher at GRAME and one of the main developer of \F{} will join the team. 

The two other academic partners of the project will be INSA-Lyon through Tanguy Risset and Florent de Dinechin at the CITI (Center of Innovation in Telecommunications and Integration of Service) and Centrale-Lyon through Pierre Lecomte and Sebastien Ollivier at the Laboratoire de Mécanique des Fluides et d'Acoustique (LMFA). TODO: something about CITI. TODO: something about LMFA.

\paragraph{Human Resources}

\paragraph{Project Organization}

The project is organized in 6 workpackages for a total of 42 months, as detailed in Figure~\ref{fig:wp}. \textit{WP0} deals with management, coordination and dissemination. \textit{WP1} is the heart of the project and the main focus of the PhD. It will deal with adapting the \F{} compiler to generate ready-to-use efficient FPGA IPs. \textit{WP2} will begin at the same time as \textit{WP1} and will focus on implementing the hardware platform (a multichannel FPGA-based audio processor) that will be used throughout the project. \textit{WP3} will leverage the results from \textit{WP1} and \textit{WP2} to implement a spatial reverberation system in the LMFA sound spatialization system that will benefit directly from the computational power of the FPGA. % RM: am I right to say that? Does it have a more official name?
\textit{WP4} will focus on the development of a hardware and software platform for high efficiency and ultra-low-latency audio signal processing and synthesis. This platform will be controllable through a user interface as well as standard communication protocols used in the field of music (i.e., MIDI, OSC, etc.).
\textit{WP5} will involve an artist/composer/postdoc who will adapt/use/abuse the technology developed in the previous workpackages to create a musical piece that will be produced with the help of GRAME-CNCM's production department. % RM: yes? no? possible? bad idea?
Finally, \textit{WP6} will apply the platform developed in \textit{WP1} and \textit{WP2} to acoustics active control. The 2 postdocs linkeds to \textit{WP5} and \textit{WP6} will be led to collaborate. 

\begin{figure}[h]
  \centering
  \includegraphics[width=\columnwidth]{img/wp}
  \caption{\PP{} project organization and planning.}
  \label{fig:wp}
\end{figure}

\paragraph{Budget (j'ai laissé le budget pour voir tableau avec spreadtab}

\begin{center}\small
  \begin{spreadtab}{{tabular}{|c|c|c|c|c|c|c|c|c||c|}}
\hline
 &@Insa & \multicolumn{3}{|c|}{@Centrale}  & @Qinteq & @eVaderis  & @Hager & @EDF &  @Total \\ 
\cline{3-5} & @Citi & @Ampere & @INL & @LTDS & & & & &\\ 
 & @(rate 100\%) & @(100\%) & @(100\%) & @(100\%) &   @(rate 35\%)&  @(rate 35\%)  &@(rate 30\%) &@(rate 30\%) &  @(k\euro)\\ \hline \hline
@Man Month ANR & 42 & 20& 20 &20  & 3 & 6 & 12 & 9 & \\ \hline
@Staff (k\euro)   & 148 & 78& 78 & 78 & 17 & 34 & 44 & 45 & sum(b5:i5) \\ \hline
@Equipment  (k\euro)   &  20 & 10 & 5 & 5  & & & & &sum(b6:i6) \\  \hline
@Travel  (k\euro)    &  20 & 5 & 5 & 5 &5 & 5 & 5 & 5 & sum(b7:i7)\\  \hline
@Management  (k\euro)    &  15 & 5 &5 & 5  & 5 & 5 & 5 & 5 & sum(b8:i8) \\
\hline\hline
@Total requested (k\euro)     & sum(b5:b8)  & sum(c5:c8)    & sum(d5:d8) & sum(e5:e8)& sum(f5:f8) & sum(g5:g8)& sum(h5:h8)& sum(i5:i8)& sum(j5:j8)  \\ \hline
\end{spreadtab}

\end{center}






%\section{Impact et retombées du projet}
\section{Project impact and benefits}

\bibliographystyle{plain}
\bibliography{main}

\newpage
\section{A enlever avant de soumettre: Taux de précarité (pas vérifié la formule 2018)}
{Man month repartition per  partner }

\begin{spreadtab}{{tabular}{|c||p{2.4cm}|p{2cm}|p{2.7cm}|p{2.5cm}||p{1cm}|}}
\hline
@Institution &
@permanent
 (institution) &
@permanent 
 (ANR) &
@Non-permanent
 (ANR) &
@PhD thesis and internship &
@Total
 \\ \hline \hline
@Insa Citi 	& 36 	& 	&  24	& 18 & sum(b2:e2) \\
\hline
@Centrale  	&  28	& 	&  24	&   36 & sum(b3:e3) \\
\hline
@Qinteq 	&  18	& 6  	&	& & sum(b4:e4) \\
\hline
@eVaderis 	&  18	& 6  	&	& & sum(b5:e5) \\
\hline
@Hager	&  18	& 6  	&	& & sum(b6:e6) \\
\hline \hline 
@Total 	&  sum(b2:b6)	&  sum(c2:c6)	& sum(d2:d6) & sum(e2:e6)  &  sum(b7:e7)\\
\hline
\multicolumn{6}{|l|}{\em taux de précarité (<<d7>>/(<<b7>>+<<c7>>+<<d7>>)) :  :={round(d7/sum(b7:d7),3)}} \\
\hline
\end{spreadtab}


\end{document}


\end{document}

